"""
æµ‹è¯• ETL åˆ‡åˆ†åŠŸèƒ½
éªŒè¯éä»£ç æ–‡ä»¶ï¼ˆtxtã€pdfã€docxã€mdï¼‰çš„åˆ‡åˆ†é€»è¾‘æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from langchain_community.document_loaders import TextLoader
from src.rag.etl import ContentProcessor, CHINESE_SEPARATORS, MARKDOWN_SEPARATORS

def create_long_test_document():
    """åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿé•¿çš„æµ‹è¯•æ–‡æ¡£ï¼ˆè¶…è¿‡ CHUNK_SIZE=800ï¼‰"""
    test_text = """
# å…¬å¸å‘˜å·¥æ‰‹å†Œ - å®Œæ•´ç‰ˆ

## ç¬¬ä¸€ç«  å…¬å¸ç®€ä»‹

æˆ‘ä»¬å…¬å¸æˆç«‹äº2010å¹´ï¼Œæ˜¯ä¸€å®¶ä¸“æ³¨äºäººå·¥æ™ºèƒ½æŠ€æœ¯ç ”å‘çš„é«˜ç§‘æŠ€ä¼ä¸šã€‚å…¬å¸æ€»éƒ¨ä½äºåŒ—äº¬ï¼Œåœ¨ä¸Šæµ·ã€æ·±åœ³ã€æˆéƒ½å‡è®¾æœ‰åˆ†å…¬å¸ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒå›¢é˜Ÿæ¥è‡ªäºå›½å†…å¤–çŸ¥åç§‘æŠ€å…¬å¸ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è¡Œä¸šç»éªŒå’ŒæŠ€æœ¯ç§¯ç´¯ã€‚

æˆ‘ä»¬çš„ä½¿å‘½æ˜¯ï¼šè®©äººå·¥æ™ºèƒ½æŠ€æœ¯é€ ç¦æ¯ä¸€ä¸ªæ™®é€šäººã€‚æˆ‘ä»¬çš„æ„¿æ™¯æ˜¯æˆä¸ºå…¨çƒé¢†å…ˆçš„äººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆæä¾›å•†ã€‚æˆ‘ä»¬åšä¿¡ï¼Œé€šè¿‡æŒç»­çš„æŠ€æœ¯åˆ›æ–°å’Œä¼˜è´¨çš„æœåŠ¡ï¼Œèƒ½å¤Ÿä¸ºå®¢æˆ·åˆ›é€ æ›´å¤§çš„ä»·å€¼ã€‚

## ç¬¬äºŒç«  ä¼‘å‡åˆ¶åº¦

### 2.1 å¹´å‡è§„å®š

å…¨èŒå‘˜å·¥å…¥èŒæ»¡ä¸€å¹´åï¼Œå¯äº«å—å¸¦è–ªå¹´å‡ã€‚å¹´å‡å¤©æ•°æ ¹æ®å·¥é¾„ç¡®å®šï¼š
- å·¥é¾„1-3å¹´ï¼š5å¤©å¹´å‡
- å·¥é¾„3-5å¹´ï¼š10å¤©å¹´å‡
- å·¥é¾„5å¹´ä»¥ä¸Šï¼š15å¤©å¹´å‡

å¹´å‡åº”åœ¨å½“å¹´å†…ä½¿ç”¨å®Œæ¯•ï¼Œå¦‚å› å·¥ä½œåŸå› æ— æ³•ä½¿ç”¨ï¼Œç»éƒ¨é—¨ç»ç†æ‰¹å‡†å¯å»¶è‡³æ¬¡å¹´3æœˆåº•å‰ä½¿ç”¨ã€‚å‘˜å·¥ç¦»èŒæ—¶æœªä½¿ç”¨çš„å¹´å‡å°†æŒ‰æ—¥å·¥èµ„æŠ˜ç®—å‘æ”¾ã€‚

### 2.2 ç—…å‡è§„å®š

å‘˜å·¥å› ç—…éœ€è¦è¯·å‡ï¼Œéœ€æä¾›åŒ»é™¢å¼€å…·çš„ç—…å‡è¯æ˜ã€‚ç—…å‡æœŸé—´å·¥èµ„æŒ‰åŸºæœ¬å·¥èµ„çš„80%å‘æ”¾ã€‚è¿ç»­ç—…å‡è¶…è¿‡30å¤©è€…ï¼Œéœ€ç»äººåŠ›èµ„æºéƒ¨é—¨å®¡æ‰¹ã€‚ç—…å‡æœŸé—´ï¼Œå‘˜å·¥åº”ä¿æŒé€šè®¯ç•…é€šï¼Œé…åˆå…¬å¸äº†è§£ç—…æƒ…è¿›å±•ã€‚

### 2.3 å©šå‡è§„å®š

å‘˜å·¥ç»“å©šå¯äº«å—3å¤©å©šå‡ï¼Œæ™šå©šå‘˜å·¥ï¼ˆç”·25å‘¨å²ã€å¥³23å‘¨å²ä»¥ä¸Šï¼‰å¯äº«å—10å¤©å©šå‡ã€‚å©šå‡åº”åœ¨ç»“å©šç™»è®°å6ä¸ªæœˆå†…ä½¿ç”¨å®Œæ¯•ï¼Œéœ€æå‰ä¸€å‘¨å‘éƒ¨é—¨ç»ç†æäº¤ç”³è¯·ã€‚

### 2.4 äº§å‡è§„å®š

å¥³æ€§å‘˜å·¥ç”Ÿè‚²äº«å—98å¤©äº§å‡ï¼Œéš¾äº§å¢åŠ 15å¤©ï¼Œå¤šèƒèƒæ¯å¤šä¸€ä¸ªå©´å„¿å¢åŠ 15å¤©ã€‚ç”·å‘˜å·¥å¯äº«å—15å¤©é™ªäº§å‡ã€‚äº§å‡æœŸé—´äº«å—ç”Ÿè‚²æ´¥è´´ã€‚

## ç¬¬ä¸‰ç«  è–ªé…¬ç¦åˆ©

### 3.1 è–ªèµ„ç»“æ„

å‘˜å·¥è–ªèµ„ç”±ä»¥ä¸‹å‡ éƒ¨åˆ†ç»„æˆï¼š
- åŸºæœ¬å·¥èµ„ï¼šæ ¹æ®å²—ä½ç­‰çº§å’Œå·¥ä½œç»éªŒç¡®å®š
- ç»©æ•ˆå¥–é‡‘ï¼šæ ¹æ®å­£åº¦ç»©æ•ˆè€ƒæ ¸ç»“æœå‘æ”¾
- å¹´ç»ˆå¥–é‡‘ï¼šæ ¹æ®å…¬å¸å¹´åº¦ç»è¥ä¸šç»©å’Œä¸ªäººè¡¨ç°å‘æ”¾
- è‚¡ç¥¨æœŸæƒï¼šé¢å‘æ ¸å¿ƒå‘˜å·¥ï¼ŒæŒ‰å…¬å¸æœŸæƒè®¡åˆ’æ‰§è¡Œ

è–ªèµ„å‘æ”¾æ—¶é—´ä¸ºæ¯æœˆ15æ—¥ï¼Œå¦‚é‡èŠ‚å‡æ—¥æå‰è‡³æœ€è¿‘çš„å·¥ä½œæ—¥ã€‚

### 3.2 ç¦åˆ©å¾…é‡

å…¬å¸ä¸ºå‘˜å·¥æä¾›ä»¥ä¸‹ç¦åˆ©ï¼š
- äº”é™©ä¸€é‡‘ï¼šå…»è€ä¿é™©ã€åŒ»ç–—ä¿é™©ã€å¤±ä¸šä¿é™©ã€å·¥ä¼¤ä¿é™©ã€ç”Ÿè‚²ä¿é™©ã€ä½æˆ¿å…¬ç§¯é‡‘
- è¡¥å……åŒ»ç–—ä¿é™©ï¼šé¢å¤–æŠ¥é”€é—¨è¯Šå’Œä½é™¢è´¹ç”¨
- å¹´åº¦ä½“æ£€ï¼šæ¯å¹´ä¸€æ¬¡å…è´¹å¥åº·ä½“æ£€
- èŠ‚æ—¥ç¦åˆ©ï¼šæ˜¥èŠ‚ã€ä¸­ç§‹ç­‰ä¼ ç»ŸèŠ‚æ—¥å‘æ”¾ç¤¼å“æˆ–è´­ç‰©å¡
- ç”Ÿæ—¥ç¦åˆ©ï¼šå‘˜å·¥ç”Ÿæ—¥å½“æœˆå‘æ”¾ç”Ÿæ—¥ç¤¼ç‰©
- å›¢å»ºæ´»åŠ¨ï¼šæ¯å­£åº¦ç»„ç»‡ä¸€æ¬¡éƒ¨é—¨å›¢å»ºæ´»åŠ¨

### 3.3 åŠ ç­åˆ¶åº¦

å…¬å¸å®è¡Œæ ‡å‡†å·¥æ—¶åˆ¶ï¼Œæ¯æ—¥å·¥ä½œ8å°æ—¶ã€‚å› å·¥ä½œéœ€è¦åŠ ç­çš„ï¼Œéœ€æå‰ç”³è¯·å¹¶è·å¾—æ‰¹å‡†ã€‚å·¥ä½œæ—¥åŠ ç­æŒ‰1.5å€å·¥èµ„è®¡ç®—ï¼Œå‘¨æœ«åŠ ç­æŒ‰2å€å·¥èµ„è®¡ç®—ï¼Œæ³•å®šèŠ‚å‡æ—¥åŠ ç­æŒ‰3å€å·¥èµ„è®¡ç®—ã€‚ä¹Ÿå¯é€‰æ‹©è°ƒä¼‘ä»£æ›¿åŠ ç­è´¹ã€‚

## ç¬¬å››ç«  èŒä¸šå‘å±•

### 4.1 æ™‹å‡é€šé“

å…¬å¸ä¸ºå‘˜å·¥æä¾›ç®¡ç†åºåˆ—å’Œä¸“ä¸šåºåˆ—åŒé€šé“å‘å±•è·¯å¾„ã€‚ç®¡ç†åºåˆ—åŒ…æ‹¬ï¼šä¸»ç®¡ã€ç»ç†ã€é«˜çº§ç»ç†ã€æ€»ç›‘ã€å‰¯æ€»è£ã€‚ä¸“ä¸šåºåˆ—åŒ…æ‹¬ï¼šåˆçº§å·¥ç¨‹å¸ˆã€ä¸­çº§å·¥ç¨‹å¸ˆã€é«˜çº§å·¥ç¨‹å¸ˆã€èµ„æ·±å·¥ç¨‹å¸ˆã€ä¸“å®¶ã€é¦–å¸­ä¸“å®¶ã€‚

### 4.2 åŸ¹è®­ä½“ç³»

å…¬å¸å»ºç«‹äº†å®Œå–„çš„åŸ¹è®­ä½“ç³»ï¼ŒåŒ…æ‹¬ï¼š
- æ–°å‘˜å·¥å…¥èŒåŸ¹è®­ï¼šå¸®åŠ©æ–°å‘˜å·¥å¿«é€Ÿèå…¥å…¬å¸
- å²—ä½æŠ€èƒ½åŸ¹è®­ï¼šæå‡å‘˜å·¥ä¸“ä¸šæŠ€èƒ½
- ç®¡ç†èƒ½åŠ›åŸ¹è®­ï¼šåŸ¹å…»ç®¡ç†äººæ‰
- å¤–éƒ¨åŸ¹è®­ï¼šèµ„åŠ©å‘˜å·¥å‚åŠ å¤–éƒ¨ä¸“ä¸šåŸ¹è®­
- åœ¨çº¿å­¦ä¹ å¹³å°ï¼šæä¾›ä¸°å¯Œçš„åœ¨çº¿è¯¾ç¨‹èµ„æº

## ç¬¬äº”ç«  è¡Œä¸ºè§„èŒƒ

### 5.1 å·¥ä½œçºªå¾‹

å‘˜å·¥åº”éµå®ˆä»¥ä¸‹å·¥ä½œçºªå¾‹ï¼š
- å‡†æ—¶ä¸Šä¸‹ç­ï¼Œä¸è¿Ÿåˆ°æ—©é€€
- å·¥ä½œæ—¶é—´ä¸åšä¸å·¥ä½œæ— å…³çš„äº‹æƒ…
- ä¿æŒåŠå…¬ç¯å¢ƒæ•´æ´
- ä¿å®ˆå…¬å¸å•†ä¸šç§˜å¯†
- ç»´æŠ¤å…¬å¸å½¢è±¡å’Œå£°èª‰

### 5.2 è€ƒå‹¤åˆ¶åº¦

å…¬å¸å®è¡Œæ‰“å¡è€ƒå‹¤åˆ¶åº¦ï¼Œå‘˜å·¥åº”æ¯æ—¥ä¸Šä¸‹ç­æ‰“å¡ã€‚å¦‚å› ç‰¹æ®Šæƒ…å†µæ— æ³•æ‰“å¡ï¼Œåº”åœ¨å½“æ—¥å‘äººäº‹éƒ¨é—¨æŠ¥å¤‡ã€‚è¿ç»­ä¸‰å¤©æœªæ‰“å¡ä¸”æœªæŠ¥å¤‡è€…ï¼Œè§†ä¸ºæ—·å·¥å¤„ç†ã€‚
"""
    return test_text


def test_chinese_separators():
    """æµ‹è¯•ä¸­æ–‡åˆ†éš”ç¬¦åˆ‡åˆ†"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•1: ä¸­æ–‡åˆ†éš”ç¬¦åˆ‡åˆ†")
    print("=" * 60)
    
    processor = ContentProcessor()
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ–‡æ¡£
    from langchain_core.documents import Document
    test_text = create_long_test_document()
    
    doc = Document(
        page_content=test_text,
        metadata={"source": "test.txt", "file_type": ".txt"}
    )
    
    # æ‰§è¡Œåˆ‡åˆ†
    chunks = processor.split_documents([doc])
    
    print(f"\nğŸ“Š åˆ‡åˆ†ç»“æœ:")
    print(f"   - åŸå§‹æ–‡æ¡£é•¿åº¦: {len(test_text)} å­—ç¬¦")
    print(f"   - åˆ‡åˆ†åç‰‡æ®µæ•°: {len(chunks)} ä¸ª")
    print(f"   - CHUNK_SIZE: {processor.chunk_size}")
    print(f"   - CHUNK_OVERLAP: {processor.chunk_overlap}")
    
    print(f"\nğŸ“„ å„ç‰‡æ®µé¢„è§ˆ:")
    for i, chunk in enumerate(chunks[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        content = chunk.page_content.strip()
        preview = content[:100] + "..." if len(content) > 100 else content
        print(f"\n   [ç‰‡æ®µ {i+1}] (é•¿åº¦: {len(content)})")
        print(f"   {preview}")
    
    if len(chunks) > 5:
        print(f"\n   ... è¿˜æœ‰ {len(chunks) - 5} ä¸ªç‰‡æ®µ")
    
    # éªŒè¯åˆ‡åˆ†æ˜¯å¦åˆç†
    print(f"\nâœ… éªŒè¯ç»“æœ:")
    all_valid = True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç‰‡æ®µè¶…å‡ºé™åˆ¶å¤ªå¤š
    oversized = [c for c in chunks if len(c.page_content) > processor.chunk_size * 1.2]
    if oversized:
        print(f"   âš ï¸ æœ‰ {len(oversized)} ä¸ªç‰‡æ®µè¶…è¿‡ CHUNK_SIZE 120%")
        all_valid = False
    else:
        print(f"   âœ… æ‰€æœ‰ç‰‡æ®µå¤§å°åˆç† (æ— è¶…è¿‡ {processor.chunk_size * 1.2} å­—ç¬¦çš„ç‰‡æ®µ)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç‰‡æ®µå¤ªå°ï¼ˆå¯èƒ½åˆ‡åˆ†è¿‡åº¦ï¼‰
    tiny = [c for c in chunks if len(c.page_content) < 50]
    if len(tiny) > len(chunks) * 0.3:  # è¶…è¿‡30%å¤ªå°
        print(f"   âš ï¸ æœ‰ {len(tiny)} ä¸ªç‰‡æ®µå°äº50å­—ç¬¦ ({len(tiny)/len(chunks)*100:.1f}%)")
    else:
        print(f"   âœ… åˆ‡åˆ†ç²’åº¦åˆç† (å°ç‰‡æ®µå æ¯”: {len(tiny)/len(chunks)*100:.1f}%)")
    
    # æ£€æŸ¥é‡å æ•ˆæœ
    if len(chunks) > 1:
        print(f"   âœ… æˆåŠŸåˆ‡åˆ†ä¸ºå¤šä¸ªç‰‡æ®µï¼Œé‡å åŠŸèƒ½å·²ç”Ÿæ•ˆ")
    
    return all_valid


def test_markdown_separators():
    """æµ‹è¯• Markdown åˆ†éš”ç¬¦åˆ‡åˆ†"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•2: Markdownåˆ†éš”ç¬¦åˆ‡åˆ†")
    print("=" * 60)
    
    processor = ContentProcessor()
    
    from langchain_core.documents import Document
    test_text = create_long_test_document()
    
    doc = Document(
        page_content=test_text,
        metadata={"source": "test.md", "file_type": ".md"}
    )
    
    # æ‰§è¡Œåˆ‡åˆ†
    chunks = processor.split_documents([doc])
    
    print(f"\nğŸ“Š åˆ‡åˆ†ç»“æœ:")
    print(f"   - åŸå§‹æ–‡æ¡£é•¿åº¦: {len(test_text)} å­—ç¬¦")
    print(f"   - åˆ‡åˆ†åç‰‡æ®µæ•°: {len(chunks)} ä¸ª")
    
    print(f"\nğŸ“„ å„ç‰‡æ®µé¢„è§ˆ:")
    for i, chunk in enumerate(chunks[:3]):
        content = chunk.page_content.strip()
        preview = content[:100] + "..." if len(content) > 100 else content
        print(f"\n   [ç‰‡æ®µ {i+1}] (é•¿åº¦: {len(content)})")
        print(f"   {preview}")
    
    # æ£€æŸ¥æ˜¯å¦æŒ‰æ ‡é¢˜åˆ‡åˆ†
    has_title_start = sum(1 for c in chunks if c.page_content.strip().startswith('#'))
    print(f"\n   ğŸ“ ä»¥æ ‡é¢˜å¼€å¤´çš„ç‰‡æ®µæ•°: {has_title_start}/{len(chunks)}")
    
    print(f"\nâœ… Markdown åˆ‡åˆ†æµ‹è¯•å®Œæˆ")
    return True


def test_settings():
    """æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•3: é…ç½®åŠ è½½éªŒè¯")
    print("=" * 60)
    
    from config.settings import settings
    
    print(f"\nğŸ“‹ å½“å‰é…ç½®:")
    print(f"   - CHUNK_SIZE: {settings.CHUNK_SIZE}")
    print(f"   - CHUNK_OVERLAP: {settings.CHUNK_OVERLAP}")
    print(f"   - EMBEDDING_MODEL: {settings.EMBEDDING_MODEL}")
    
    # éªŒè¯é…ç½®åˆç†æ€§
    if settings.CHUNK_SIZE < 200:
        print("   âš ï¸ CHUNK_SIZE å¯èƒ½å¤ªå°")
        return False
    if settings.CHUNK_OVERLAP > settings.CHUNK_SIZE * 0.3:
        print("   âš ï¸ CHUNK_OVERLAP å æ¯”è¿‡é«˜")
        return False
    
    print("   âœ… é…ç½®åˆç†")
    return True


def main():
    print("ğŸš€ å¯åŠ¨ ETL åˆ‡åˆ†åŠŸèƒ½æµ‹è¯•...\n")
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(("é…ç½®åŠ è½½", test_settings()))
    results.append(("ä¸­æ–‡åˆ‡åˆ†", test_chinese_separators()))
    results.append(("Markdownåˆ‡åˆ†", test_markdown_separators()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•æ±‡æ€»")
    print("=" * 60)
    
    all_passed = True
    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"   {name}: {status}")
        if not passed:
            all_passed = False
    
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ETL åˆ‡åˆ†åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹è¯¦æƒ…")
    print("=" * 60)


if __name__ == "__main__":
    main()