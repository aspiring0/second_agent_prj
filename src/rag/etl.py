# src/rag/etl.py
import os
import tempfile
from pathlib import Path
from typing import List

# å¼•å…¥ Streamlit çš„æ–‡ä»¶å¯¹è±¡ç±»å‹æç¤º (å¯é€‰ï¼Œä¸ºäº†ä»£ç è§„èŒƒ)
from streamlit.runtime.uploaded_file_manager import UploadedFile

from langchain_community.document_loaders import (
    TextLoader, 
    PyPDFLoader, 
    Docx2txtLoader, 
    UnstructuredMarkdownLoader
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from config.settings import settings
from src.utils.logger import setup_logger

logger = setup_logger("RAG_ETL")

class ContentProcessor:
    def __init__(self):
        self.chunk_size = settings.CHUNK_SIZE
        self.chunk_overlap = settings.CHUNK_OVERLAP

    def load_uploaded_files(self, uploaded_files: List[UploadedFile]):
        """
        ç›´æ¥å¤„ç†å†…å­˜ä¸­çš„æ–‡ä»¶å¯¹è±¡ï¼Œä¸æŒä¹…åŒ–ä¿å­˜åˆ°ç£ç›˜ã€‚
        ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æŠ€æœ¯é€‚é… LangChain Loaderã€‚
        """
        documents = []
        
        for up_file in uploaded_files:
            # up_file.name æ˜¯æ–‡ä»¶å (e.g., "report.pdf")
            # up_file.getvalue() æ˜¯äºŒè¿›åˆ¶å†…å®¹
            
            try:
                # 1. åˆ›å»ºä¸´æ—¶æ–‡ä»¶ (TempFile)
                # delete=False æ˜¯ä¸ºäº†å…¼å®¹ Windowsï¼Œå¿…é¡»å…ˆå…³é—­æ–‡ä»¶æ‰èƒ½è®© Loader å»å†æ¬¡æ‰“å¼€è¯»å–
                suffix = Path(up_file.name).suffix
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                    tmp_file.write(up_file.getvalue())
                    tmp_path = tmp_file.name  # è·å–ä¸´æ—¶æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
                
                # 2. é€‰æ‹©åŠ è½½å™¨å¹¶è¯»å–
                logger.info(f"ğŸ“„ æ­£åœ¨å†…å­˜å¤„ç†: {up_file.name}")
                loader = self._select_loader(Path(tmp_path))
                
                if loader:
                    docs = loader.load()
                    
                    # 3. å…³é”®ä¿®æ­£ï¼šå…ƒæ•°æ®ä¿®å¤
                    # åŠ è½½å™¨è¯»çš„æ˜¯ä¸´æ—¶è·¯å¾„ (å¦‚ /tmp/tmp8x9s.pdf)ï¼Œ
                    # æˆ‘ä»¬è¦æŠŠ source æ”¹å›åŸå§‹æ–‡ä»¶å (report.pdf)ï¼Œå¦åˆ™å¼•ç”¨ä¼šä¹±ç 
                    for doc in docs:
                        doc.metadata["source"] = up_file.name
                        
                    documents.extend(docs)
                
                # 4. æ¸…ç†ç°åœºï¼šåˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.remove(tmp_path)
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {up_file.name} å¤±è´¥: {e}")
                # ç¡®ä¿å‘ç”Ÿé”™è¯¯ä¹Ÿåˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if 'tmp_path' in locals() and os.path.exists(tmp_path):
                    os.remove(tmp_path)

        logger.info(f"âœ… å†…å­˜åŠ è½½å®Œæˆ: å…±è§£æ {len(documents)} ä»½æ–‡æ¡£")
        return documents

    def _select_loader(self, file_path: Path):
        """æ ¹æ®ä¸´æ—¶æ–‡ä»¶çš„åç¼€é€‰æ‹©åŠ è½½å™¨"""
        suffix = file_path.suffix.lower()
        
        if suffix == ".txt":
            return TextLoader(str(file_path), encoding="utf-8")
        elif suffix == ".md":
            return UnstructuredMarkdownLoader(str(file_path))
        elif suffix == ".pdf":
            return PyPDFLoader(str(file_path))
        elif suffix == ".docx":
            return Docx2txtLoader(str(file_path))
        elif suffix in [".py", ".js", ".java", ".c", ".cpp"]:
            return TextLoader(str(file_path), encoding="utf-8")
        else:
            logger.warning(f"âš ï¸ æš‚ä¸æ”¯æŒæ ¼å¼: {suffix}")
            return None

    def split_documents(self, documents):
        if not documents:
            return []
            
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "class ", "def ", " ", ""]
        )
        chunks = text_splitter.split_documents(documents)
        return chunks